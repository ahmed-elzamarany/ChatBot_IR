{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:32:08.378543Z",
     "iopub.status.busy": "2021-06-22T14:32:08.378079Z",
     "iopub.status.idle": "2021-06-22T14:32:08.384576Z",
     "shell.execute_reply": "2021-06-22T14:32:08.383091Z",
     "shell.execute_reply.started": "2021-06-22T14:32:08.378506Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:32:13.561105Z",
     "iopub.status.busy": "2021-06-22T14:32:13.560747Z",
     "iopub.status.idle": "2021-06-22T14:32:15.357037Z",
     "shell.execute_reply": "2021-06-22T14:32:15.356063Z",
     "shell.execute_reply.started": "2021-06-22T14:32:13.561073Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "#Importing the stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:32:15.394579Z",
     "iopub.status.busy": "2021-06-22T14:32:15.394246Z",
     "iopub.status.idle": "2021-06-22T14:32:23.689487Z",
     "shell.execute_reply": "2021-06-22T14:32:23.688128Z",
     "shell.execute_reply.started": "2021-06-22T14:32:15.394541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initializing the WordNetLemmatizer\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#A dictionary reference for replacing special characters\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemTokens(tokens):\n",
    "       return [lemmer.lemmatize(token,'v') for token in tokens if token not in set(stopwords.words('english'))]\n",
    "def LemNormalize(text):\n",
    "       return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "# tokenized_dataset.drop_duplicates(subset =\"utterance\",keep = \"first\", inplace = True)\n",
    "# tokenized_dataset['tokenized_text']=tokenized_dataset.utterance.apply(lambda row: LemNormalize(row))\n",
    "def LemAllTokens(tokens):\n",
    "       return [lemmer.lemmatize(token,'v') for token in tokens]\n",
    "def LemAllNormalize(text):\n",
    "       return LemAllTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:32:25.870795Z",
     "iopub.status.busy": "2021-06-22T14:32:25.870243Z",
     "iopub.status.idle": "2021-06-22T14:32:25.884358Z",
     "shell.execute_reply": "2021-06-22T14:32:25.883149Z",
     "shell.execute_reply.started": "2021-06-22T14:32:25.870737Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    tennisrobo_response = ''\n",
    "    article_sentences=prompts.copy()\n",
    "    article_sentences.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('english'))\n",
    "    all_word_vectors = word_vectorizer.fit_transform(article_sentences)\n",
    "    similar_prompt_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_prompt_number = similar_prompt_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similar_prompt_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched != 0 :\n",
    "        utterances = dic[article_sentences[similar_prompt_number]].copy()\n",
    "        utterances.append(user_input)\n",
    "        word_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('english'))\n",
    "        all_word_vectors = word_vectorizer.fit_transform(utterances)\n",
    "        similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "        similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "        i= -2\n",
    "        while(similar_sentence_number==len(utterances)-2):\n",
    "            i-=1\n",
    "            similar_prompt_number = similar_prompt_vector_values.argsort()[0][-2]\n",
    "            utterances = dic[article_sentences[similar_prompt_number]].copy()\n",
    "            utterances.append(user_input)\n",
    "            word_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopwords.words('english'))\n",
    "            all_word_vectors = word_vectorizer.fit_transform(utterances)\n",
    "            similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "            similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "        tennisrobo_response = tennisrobo_response + utterances[similar_sentence_number+1]\n",
    "        print(\"prompt : \",article_sentences[similar_prompt_number])\n",
    "        print(\"original  : \",utterances[similar_sentence_number])\n",
    "        return tennisrobo_response\n",
    "    else:\n",
    "        tennisrobo_response = tennisrobo_response + \"I don't know what to say, but I undertand that you are sad\"\n",
    "        return tennisrobo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReady():\n",
    "    loaded_model = pickle.load(open('SentimentModel.sav', 'rb'))\n",
    "    Countvectorizer=pickle.load(open('Countvectorizer.pickle', 'rb'))\n",
    "    indeces_to_delete=pickle.load(open('indeces_to_delete.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(sentence):\n",
    "    loaded_model = pickle.load(open('SentimentModel.sav', 'rb'))\n",
    "    Countvectorizer=pickle.load(open('Countvectorizer.pickle', 'rb'))\n",
    "    indeces_to_delete=pickle.load(open('indeces_to_delete.pickle', 'rb'))\n",
    "    getReady()\n",
    "    X_new = Countvectorizer.transform(sentence)\n",
    "    X_new_simple = np.delete(X_new.toarray(), indeces_to_delete, axis=1)\n",
    "    return loaded_model.predict(X_new_simple)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentiment(['I have cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T17:46:14.414559Z",
     "iopub.status.busy": "2021-06-22T17:46:14.414149Z",
     "iopub.status.idle": "2021-06-22T17:46:14.433097Z",
     "shell.execute_reply": "2021-06-22T17:46:14.432090Z",
     "shell.execute_reply.started": "2021-06-22T17:46:14.414526Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(user_input,name):\n",
    "    word_vectorizer = pickle.load(open(name+'_word_vectorizer.sav', 'rb'))\n",
    "    all_word_vectors=pickle.load(open(name+'_all_word_vectors.pickle', 'rb'))\n",
    "    utterances=pickle.load(open(name+'_utterance.pickle', 'rb'))\n",
    "    prompts_sentences=pickle.load(open(name+'_prompts_sentences.pickle', 'rb'))\n",
    "    tennisrobo_response = ''\n",
    "    user_input_vector= word_vectorizer.transform([user_input])\n",
    "    similar_prompt_vector_values = cosine_similarity(user_input_vector[0], all_word_vectors)\n",
    "    similar_sentence_number = similar_prompt_vector_values.argsort()[0][-1]\n",
    "                                      \n",
    "    matched_vector = similar_prompt_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-1]\n",
    "    if vector_matched != 0 and similar_sentence_number< len(utterances)-1:\n",
    "        first = '' + utterances[similar_sentence_number+1]\n",
    "        similar_sentence_second_number = similar_prompt_vector_values.argsort()[0][-2]\n",
    "        second = '' + utterances[similar_sentence_second_number+1]\n",
    "        similar_sentence_third_number = similar_prompt_vector_values.argsort()[0][-3]\n",
    "        third = '' + utterances[similar_sentence_third_number+1]\n",
    "#         print(\"first : \",first)\n",
    "#         print(matched_vector[-1])\n",
    "#         print(\"second : \",second)\n",
    "#         print(matched_vector[-2])\n",
    "#         print(\"third : \",third)\n",
    "#         print(matched_vector[-3])\n",
    "        Allreplies=[user_input,first,second,third]\n",
    "        Allprompts=[user_input,prompts_sentences[similar_sentence_number],prompts_sentences[similar_sentence_second_number],prompts_sentences[similar_sentence_third_number]]\n",
    "        Countvectorizer = CountVectorizer(tokenizer = LemAllNormalize, ngram_range=(1,1))\n",
    "        counts_vector= Countvectorizer.fit_transform(Allprompts)\n",
    "        count_prompt_cosine_similarity = cosine_similarity(counts_vector[0], counts_vector)\n",
    "#         print(counts_vector[0])\n",
    "        count_matched_vector = count_prompt_cosine_similarity.flatten()\n",
    "        count_matched_vector.sort()\n",
    "        fi=count_prompt_cosine_similarity.argsort()[0][0]\n",
    "#         print(Allprompts[fi],Allreplies[fi])\n",
    "#         print(count_matched_vector[0])\n",
    "        si=count_prompt_cosine_similarity.argsort()[0][1]\n",
    "#         print(Allprompts[si],Allreplies[si])\n",
    "#         print(count_matched_vector[1])\n",
    "        ti=count_prompt_cosine_similarity.argsort()[0][2]\n",
    "#         print(Allprompts[ti],Allreplies[ti])\n",
    "#         print(count_matched_vector[2])\n",
    "        foi=count_prompt_cosine_similarity.argsort()[0][3]\n",
    "#         print(Allprompts[foi],Allreplies[foi])\n",
    "#         print(count_matched_vector[3])\n",
    "        return Allreplies[ti]\n",
    "    else:\n",
    "        return \"I don't know what to say, but I undertand that you are\"+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "greeting_inputs = (\"hey\",\"I am good\", \"good morning\", \"good evening\",\"hello\", \"morning\", \"evening\", \"hi\", \"whatsup\")\n",
    "greeting_responses = [\"hey\",\"You seems happy? Is that true?\", \"hey hows you?\", \"*nods*\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you?\"]\n",
    "goodbyes_inputs = ('thanks','thank you very much', 'thank you', \"bye\",\"goodbye\",\"no\")\n",
    "goodbyes_responses = [\"Most welcome\",'thanks','thank you very much', 'thank you', \"bye\",\"goodbye\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)\n",
    "def generate_goodbyes_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in goodbyes_inputs:\n",
    "            return random.choice(goodbyes_responses)\n",
    "def wrong_sentiment(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() ==\"no\":\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venti: Hello, I am your friend Venti. Do you wanna talk a little with me? :\n",
      "yes\n",
      "Venti: You seems surprised ? Is that true?\n",
      "no, tell me about yourself\n",
      "Venti: Ok, Do you wanna talk more about it?\n",
      "yes \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'thatll', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venti:  I like to do that for people when they don't expect it or when they need it most\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a7513affbcc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinue_dialogue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mhuman_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mhuman_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhuman_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhuman_text\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'bye'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "continue_dialogue = True\n",
    "sentiment=None\n",
    "print(\"Venti: Hello, I am your friend Venti. Do you wanna talk a little with me? :\")\n",
    "while(continue_dialogue == True):\n",
    "    \n",
    "    human_text = input()\n",
    "    human_text = human_text.lower()\n",
    "    if human_text != 'bye':\n",
    "        if generate_goodbyes_response(human_text) != None:\n",
    "            continue_dialogue = False\n",
    "            print(\"Venti: \" + generate_goodbyes_response(human_text))\n",
    "        else:\n",
    "            if sentiment == None:\n",
    "                sentiment= getSentiment([human_text])\n",
    "                print(\"Venti: You seems\", sentiment, \"? Is that true?\")\n",
    "                human_text = input()\n",
    "                human_text = human_text.lower()\n",
    "                print(\"Venti: Ok, Do you wanna talk more about it?\")\n",
    "                human_text = input()\n",
    "                human_text = human_text.lower()\n",
    "                if wrong_sentiment(human_text)==True:\n",
    "                    sentiment= getSentiment([human_text])\n",
    "#                 print(\"typing...\")\n",
    "                print(\"Venti: \", generate_response(human_text,sentiment))\n",
    "            else:\n",
    "#                 print(\"typing...\")\n",
    "                print(\"Venti: \", generate_response(human_text,sentiment))\n",
    "    else:\n",
    "        continue_dialogue = False\n",
    "        print(\"Venti: Good bye and take care of yourself...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4e63d3a7e419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtranslate_v2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtranslate_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "\"\"\"Translates text into the target language.\n",
    "\n",
    "Target must be an ISO 639-1 language code.\n",
    "See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "\"\"\"\n",
    "import six\n",
    "from google.cloud import translate_v2 as translate\n",
    "def translate_text(target, text):\n",
    "\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    print(u\"Text: {}\".format(result[\"input\"]))\n",
    "    print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "\n",
    "translate_text('en', \"اهلا\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
